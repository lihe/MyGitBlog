# [Prefix-Tuning：在注意力机制中引入可学习前缀的参数高效微调方法](https://github.com/lihe/MyGitBlog/issues/7)







随着预训练语言模型规模不断扩大，全参数微调在计算成本、存储开销和稳定性方面逐渐暴露出局限性。在此背景下，一类以**冻结模型参数、仅引入少量可训练模块**为特征的参数高效微调方法（PEFT）逐渐成为主流方向。Prefix-Tuning 正是其中具有代表性的一种方法。



Prefix-Tuning 最早由 Li 和 Liang 在 2021 年提出，其核心思想是在不修改模型权重的前提下，通过在 Transformer 的注意力机制中引入可学习的前缀向量，引导模型在生成阶段表现出符合下游任务需求的行为。



------





## **方法动机与提出背景**





传统微调方法主要面临两类问题：



一方面，全参数微调需要更新大量模型权重，在大模型场景下带来显著的显存与算力压力，同时也容易引发过拟合或灾难性遗忘。

另一方面，基于自然语言提示或仅作用于输入层的 Prompt / P-Tuning 方法，对模型深层计算路径的影响有限，在复杂生成任务中控制能力不足。



Prefix-Tuning 的设计目标是在保持模型参数完全冻结的情况下，对模型的**内部推理过程**施加更直接、可控的影响。



------





## **核心思想与基本原理**



<img width="415" height="342" alt="Image" src="https://github.com/user-attachments/assets/5ce41760-fc0f-4424-8c1e-944131851c6c" />



### **注意力机制回顾**





在 Transformer 中，自注意力机制的核心计算形式为：



$\text{Attention}(Q, K, V)$



其中，查询（Q）来自当前 token 表示，键（K）和值（V）来自上下文 token 表示。注意力输出本质上是对值向量的加权组合，权重由查询与键的相似度决定。





### **Prefix-Tuning 的关键改动**





Prefix-Tuning 在 Transformer 的**每一层注意力模块中**引入一组可训练的前缀向量。这些前缀并非真实文本 token，而是连续的高维向量，用于扩展注意力中的键和值：



$K = [K_{\text{prefix}} ; K_{\text{input}}], \quad V = [V_{\text{prefix}} ; V_{\text{input}}]$



其中：



- 查询 Q 保持不变；
- 前缀向量仅参与注意力计算，不进入前馈网络；
- 前缀在同一任务中对所有输入共享。





这种设计使模型在每一层计算注意力时，都会将前缀作为潜在的重要上下文进行考虑。



------





## **Prefix-Tuning 的作用机制**





Prefix-Tuning 的有效性主要来源于以下几个方面：



**作用层级更深**

不同于仅在输入层注入信息的提示方法，Prefix-Tuning 在每一层注意力计算中引入前缀，对模型的中间表示与决策路径产生持续影响。



**摆脱自然语言约束**

前缀由连续向量构成，不受自然语言形式限制，能够在更大的表示空间中学习任务相关信息。



**直接干预注意力分布**

注意力机制决定了模型在每一层“关注什么”。通过在键和值中引入前缀，Prefix-Tuning 实际上在每一层对模型的关注重点进行调节。



从功能上看，Prefix-Tuning 相当于在模型内部构建了一段隐式的、可学习的上下文。



------





## **训练与参数规模**





Prefix-Tuning 的训练流程具有较强的工程友好性：



1. 为每一层初始化一组前缀向量（通常对应 K/V）；
2. 冻结原始 Transformer 的全部参数；
3. 前向传播时将前缀拼接到注意力的键和值中；
4. 使用下游任务损失进行反向传播；
5. 仅更新前缀相关参数。





在实际应用中，Prefix-Tuning 的参数规模通常为万级到十万级，远小于全参数微调，也通常小于基于低秩权重更新的方法。



------





## **与相关方法的关系**





从结构干预深度来看，Prefix-Tuning 位于输入级提示方法与权重级方法之间：



- Prompt Engineering 通过自然语言文本影响模型行为；
- P-Tuning 在输入 embedding 层引入可学习提示；
- Prefix-Tuning 在每一层注意力的键和值中引入前缀；
- LoRA 等方法直接修改模型权重矩阵的有效表示。





这种位置上的差异决定了 Prefix-Tuning 在控制能力与参数效率之间取得了较为平衡的效果。



------





## **优势与局限**





Prefix-Tuning 的主要优势包括：



- 参数效率高，仅需训练少量前缀向量；
- 不修改模型权重，训练与部署过程相对安全稳定；
- 对生成类任务（如摘要、翻译、对话）具有良好适应性；
- 支持多任务场景下加载不同前缀进行快速切换。





其局限性也同样明确：



- 推理阶段需额外加载前缀，带来一定计算与存储开销；
- 表达能力通常不及直接修改权重的方法；
- 实现复杂度高于仅作用于输入层的提示方法。





------





## **应用场景与实践经验**





Prefix-Tuning 更适合以下场景：



- 中等复杂度的文本生成任务；
- 下游数据规模有限；
- 对模型参数安全性要求较高；
- 多任务或多领域快速切换需求明显。





在需要显著改变模型能力或进行复杂推理、代码生成等任务时，通常需要结合或转向更强的权重级参数高效方法。



------





## **总结**





Prefix-Tuning 通过在 Transformer 每一层注意力机制中引入可学习的前缀向量，在冻结模型参数的前提下，实现了对模型生成行为的有效引导。该方法在参数效率、稳定性与控制能力之间提供了一种折中方案，是参数高效微调技术体系中的重要组成部分。



在现代大模型应用中，Prefix-Tuning 常与其他 PEFT 方法共同构成一条从“提示级控制”到“权重级适配”的连续技术路径。
